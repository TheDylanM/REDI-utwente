{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Input \u001B[0;32mIn [2]\u001B[0m, in \u001B[0;36m<cell line: 5>\u001B[0;34m()\u001B[0m\n\u001B[1;32m      3\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mnumpy\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m \u001B[38;5;21;01mnp\u001B[39;00m\n\u001B[1;32m      4\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mpandas\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m \u001B[38;5;21;01mpd\u001B[39;00m\n\u001B[0;32m----> 5\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mfinetune\u001B[39;00m\n\u001B[1;32m      6\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mimportlib\u001B[39;00m\n\u001B[1;32m      7\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mtqdm\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m tqdm\n",
      "File \u001B[0;32m~/Pycharmprojects/REDI-utwente/src/awesome_GNN/finetune.py:14\u001B[0m, in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m     12\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mtqdm\u001B[39;00m\n\u001B[1;32m     13\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mmatplotlib\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mpyplot\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m \u001B[38;5;21;01mplt\u001B[39;00m\n\u001B[0;32m---> 14\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mpytorch_grad_cam\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m GradCAM, ScoreCAM, GradCAMPlusPlus, AblationCAM, XGradCAM, EigenCAM, FullGrad\n\u001B[1;32m     15\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mpytorch_grad_cam\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mutils\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mmodel_targets\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m ClassifierOutputTarget\n\u001B[1;32m     16\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mpytorch_grad_cam\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mutils\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mimage\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m show_cam_on_image\n",
      "File \u001B[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pytorch_grad_cam/__init__.py:1\u001B[0m, in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[0;32m----> 1\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mpytorch_grad_cam\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mgrad_cam\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m GradCAM\n\u001B[1;32m      2\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mpytorch_grad_cam\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mablation_layer\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m AblationLayer, AblationLayerVit, AblationLayerFasterRCNN\n\u001B[1;32m      3\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mpytorch_grad_cam\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mablation_cam\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m AblationCAM\n",
      "File \u001B[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pytorch_grad_cam/grad_cam.py:2\u001B[0m, in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mnumpy\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m \u001B[38;5;21;01mnp\u001B[39;00m\n\u001B[0;32m----> 2\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mpytorch_grad_cam\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mbase_cam\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m BaseCAM\n\u001B[1;32m      5\u001B[0m \u001B[38;5;28;01mclass\u001B[39;00m \u001B[38;5;21;01mGradCAM\u001B[39;00m(BaseCAM):\n\u001B[1;32m      6\u001B[0m     \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m__init__\u001B[39m(\u001B[38;5;28mself\u001B[39m, model, target_layers, use_cuda\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m,\n\u001B[1;32m      7\u001B[0m                  reshape_transform\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m):\n",
      "File \u001B[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pytorch_grad_cam/base_cam.py:6\u001B[0m, in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m      4\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mtyping\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m Callable, List, Tuple\n\u001B[1;32m      5\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mpytorch_grad_cam\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mactivations_and_gradients\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m ActivationsAndGradients\n\u001B[0;32m----> 6\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mpytorch_grad_cam\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mutils\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01msvd_on_activations\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m get_2d_projection\n\u001B[1;32m      7\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mpytorch_grad_cam\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mutils\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mimage\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m scale_cam_image\n\u001B[1;32m      8\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mpytorch_grad_cam\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mutils\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mmodel_targets\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m ClassifierOutputTarget\n",
      "File \u001B[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pytorch_grad_cam/utils/__init__.py:1\u001B[0m, in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[0;32m----> 1\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mpytorch_grad_cam\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mutils\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mimage\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m deprocess_image\n\u001B[1;32m      2\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mpytorch_grad_cam\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mutils\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01msvd_on_activations\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m get_2d_projection\n\u001B[1;32m      3\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mpytorch_grad_cam\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mutils\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m model_targets\n",
      "File \u001B[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pytorch_grad_cam/utils/image.py:1\u001B[0m, in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[0;32m----> 1\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mcv2\u001B[39;00m\n\u001B[1;32m      2\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mnumpy\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m \u001B[38;5;21;01mnp\u001B[39;00m\n\u001B[1;32m      3\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mtorch\u001B[39;00m\n",
      "File \u001B[0;32m~/opt/anaconda3/lib/python3.9/site-packages/cv2/__init__.py:8\u001B[0m, in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m      5\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mimportlib\u001B[39;00m\n\u001B[1;32m      6\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01msys\u001B[39;00m\n\u001B[0;32m----> 8\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mcv2\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;241m*\u001B[39m\n\u001B[1;32m      9\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mcv2\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m _registerMatType\n\u001B[1;32m     10\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m mat_wrapper\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import finetune\n",
    "import importlib\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# detect_convergence method not finished yet...\n",
    "def detect_convergence(values):\n",
    "    steps_to_avg = 3\n",
    "\n",
    "    for idx, val in enumerate(values):\n",
    "        # print(val)\n",
    "        if len(values) - idx <= steps_to_avg:\n",
    "            print(\"Finished\")\n",
    "            break\n",
    "\n",
    "        starting_pos = idx\n",
    "\n",
    "        avg_last_three_to_six = np.mean(values[starting_pos+steps_to_avg: starting_pos+(steps_to_avg*2)])\n",
    "        avg_last_three = np.mean(values[starting_pos + steps_to_avg:])\n",
    "        increase = (avg_last_three - avg_last_three_to_six)/avg_last_three_to_six\n",
    "        print(f'starting pos: {starting_pos}|increase: {increase}')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "path_to_data = os.path.join('..', '..', 'data')\n",
    "path_to_models = os.path.join(path_to_data, 'finetuned_models')\n",
    "\n",
    "datasets = ['FGVC-Aircraft', 'StanfordCars']\n",
    "model_names = ['resnet', 'densenet', 'vgg']"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Create inside data directory, a directory for the results export\n",
    "# The results are split into directories based on their dataset\n",
    "path_to_results = os.path.join(path_to_data, 'finetuned_model_results')\n",
    "finetune.safe_mkdir(path_to_results)\n",
    "\n",
    "for dataset in datasets:\n",
    "    finetune.safe_mkdir(os.path.join(path_to_results, dataset))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "importlib.reload(finetune)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "importlib.reload(finetune)\n",
    "\n",
    "# Importing all Resnet models in StanfordCars\n",
    "models = {}\n",
    "\n",
    "for dataset in datasets:\n",
    "    path_to_model_dir = os.path.join(path_to_models, dataset, 'resnet')\n",
    "    for file_name in os.listdir(path_to_model_dir):\n",
    "        # print(f'{dataset}: {file} | {path_to_model_dir}')\n",
    "        name = file_name.split('.')[0]\n",
    "        print(name)\n",
    "        full_path = os.path.join(path_to_model_dir, file_name)\n",
    "        model_saved_state = finetune.load_checkpoint(full_path)\n",
    "        models[name] = model_saved_state"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "for file_name, model in tqdm(models.items()):\n",
    "    train_hist, train_loss, val_hist = finetune.get_information_from_checkpoint(model)\n",
    "    dataset = file_name.split('_')[1]\n",
    "    save_path = os.path.join(path_to_results, dataset)\n",
    "    content = ''.join([str(value)+'\\n' for value in val_hist])\n",
    "    finetune.write_to_file(save_path+f'/{file_name}.txt', content)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# For each dataset\n",
    "# For each architecture get the best model\n",
    "results = {}\n",
    "\n",
    "# Read all data from results directory\n",
    "for dataset in datasets:\n",
    "    path_to_results_dataset = os.path.join(path_to_results, dataset)\n",
    "    files = os.listdir(path_to_results_dataset)\n",
    "    for file_name in files[::-1]:\n",
    "        if file_name == 'resnet_FGVC-Aircraft_E50_occ0.txt':\n",
    "            print(file_name)\n",
    "            name = file_name.split('.')[0]\n",
    "            p = os.path.join(path_to_results, dataset, file_name)\n",
    "            content =  finetune.read_file(p)\n",
    "            values = [float(val) for val in content.split('\\n') if val != '']\n",
    "            results[name] = values\n",
    "            plt.plot(values)\n",
    "            break\n",
    "        # results[name] =\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}