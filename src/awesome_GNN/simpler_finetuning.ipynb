{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "import finetune\n",
    "import importlib\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import models\n",
    "import time\n",
    "import os\n",
    "import copy\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "data": {
      "text/plain": "<module 'finetune' from '/home/matteo/Documents/Studie/Master/2021-2022/REDI/Project/REDI-utwente/src/awesome_GNN/finetune.py'>"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "importlib.reload(finetune)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classifier input size: None\n",
      "batch size: 8\n",
      "num epochs: 15\n",
      "feature extract: True\n"
     ]
    }
   ],
   "source": [
    "num_classes = 196\n",
    "finetune.CLASSIFIER_NAME = 'resnet'\n",
    "finetune.NUM_EPOCHS = 15\n",
    "finetune.FEATURE_EXTRACT = True\n",
    "finetune.print_hypers() # shows that params have been modified"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ResNet(\n",
      "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
      "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): ReLU(inplace=True)\n",
      "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "  (layer1): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer2): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer3): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer4): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "  (fc): Linear(in_features=512, out_features=196, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Initialize the model for this run\n",
    "model_ft = finetune.initialize_model(num_classes, use_pretrained=True)\n",
    "\n",
    "\n",
    "# Print the model we just instantiated\n",
    "print(model_ft)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Params to learn:\n",
      "\t fc.weight\n",
      "\t fc.bias\n",
      "Epoch 0/14\n",
      "----------\n"
     ]
    }
   ],
   "source": [
    "# dataloaders_dict = finetune.dataloaders()\n",
    "finetune.finetune_model(model_ft)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Params to learn:\n",
      "\t fc.weight\n",
      "\t fc.bias\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# model_ft = model_ft.to(finetune.device)\n",
    "\n",
    "# Gather the parameters to be optimized/updated in this run. If we are\n",
    "#  finetuning we will be updating all parameters. However, if we are\n",
    "#  doing feature extract method, we will only update the parameters\n",
    "#  that we have just initialized, i.e. the parameters with requires_grad\n",
    "#  is True.\n",
    "# params_to_update = model_ft.parameters()\n",
    "# print(\"Params to learn:\")\n",
    "# if finetune.FEATURE_EXTRACT:\n",
    "#     params_to_update = []\n",
    "#     for name,param in model_ft.named_parameters():\n",
    "#         if param.requires_grad == True:\n",
    "#             params_to_update.append(param)\n",
    "#             print(\"\\t\",name)\n",
    "# else:\n",
    "#     for name,param in model_ft.named_parameters():\n",
    "#         if param.requires_grad == True:\n",
    "#             print(\"\\t\",name)\n",
    "#\n",
    "# # Observe that all parameters are being optimized\n",
    "# optimizer_ft = optim.SGD(params_to_update, lr=0.001, momentum=0.9)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/14\n",
      "----------\n",
      "train Loss: 5.2171 Acc: 0.0210\n",
      "val Loss: 5.5201 Acc: 0.0053\n",
      "\n",
      "Epoch 1/14\n",
      "----------\n",
      "train Loss: 4.7389 Acc: 0.0625\n",
      "val Loss: 5.7119 Acc: 0.0050\n",
      "\n",
      "Epoch 2/14\n",
      "----------\n",
      "train Loss: 4.4254 Acc: 0.1084\n",
      "val Loss: 5.8705 Acc: 0.0052\n",
      "\n",
      "Epoch 3/14\n",
      "----------\n",
      "train Loss: 4.1639 Acc: 0.1478\n",
      "val Loss: 6.0756 Acc: 0.0049\n",
      "\n",
      "Epoch 4/14\n",
      "----------\n",
      "train Loss: 3.9577 Acc: 0.1826\n",
      "val Loss: 6.2775 Acc: 0.0045\n",
      "\n",
      "Epoch 5/14\n",
      "----------\n",
      "train Loss: 3.7827 Acc: 0.2031\n",
      "val Loss: 6.4477 Acc: 0.0042\n",
      "\n",
      "Epoch 6/14\n",
      "----------\n",
      "train Loss: 3.6648 Acc: 0.2257\n",
      "val Loss: 6.6009 Acc: 0.0057\n",
      "\n",
      "Epoch 7/14\n",
      "----------\n",
      "train Loss: 3.5296 Acc: 0.2458\n",
      "val Loss: 6.8010 Acc: 0.0052\n",
      "\n",
      "Epoch 8/14\n",
      "----------\n",
      "train Loss: 3.4518 Acc: 0.2676\n",
      "val Loss: 6.9587 Acc: 0.0058\n",
      "\n",
      "Epoch 9/14\n",
      "----------\n",
      "train Loss: 3.3713 Acc: 0.2704\n",
      "val Loss: 7.0086 Acc: 0.0051\n",
      "\n",
      "Epoch 10/14\n",
      "----------\n",
      "train Loss: 3.2943 Acc: 0.2883\n",
      "val Loss: 7.1767 Acc: 0.0053\n",
      "\n",
      "Epoch 11/14\n",
      "----------\n",
      "train Loss: 3.2170 Acc: 0.3022\n",
      "val Loss: 7.3165 Acc: 0.0055\n",
      "\n",
      "Epoch 12/14\n",
      "----------\n",
      "train Loss: 3.1673 Acc: 0.3134\n",
      "val Loss: 7.4048 Acc: 0.0052\n",
      "\n",
      "Epoch 13/14\n",
      "----------\n",
      "train Loss: 3.1228 Acc: 0.3177\n",
      "val Loss: 7.5995 Acc: 0.0061\n",
      "\n",
      "Epoch 14/14\n",
      "----------\n",
      "train Loss: 3.0839 Acc: 0.3200\n",
      "val Loss: 7.6401 Acc: 0.0058\n",
      "\n",
      "Training complete in 26m 19s\n",
      "Best val Acc: 0.006094\n"
     ]
    }
   ],
   "source": [
    "# Setup the loss fxn\n",
    "# criterion = nn.CrossEntropyLoss()\n",
    "#\n",
    "# # Train and evaluate\n",
    "# model_ft, hist = finetune.train_model(model_ft, dataloaders_dict, criterion, optimizer_ft, num_epochs=finetune.NUM_EPOCHS, is_inception=(model_name==\"inception\"))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}