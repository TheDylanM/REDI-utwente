{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Testing setup for all models"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import torch\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import finetune\n",
    "import importlib\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "data": {
      "text/plain": "<module 'finetune' from 'C:\\\\Users\\\\dylan\\\\PycharmProjects\\\\REDI-utwente\\\\src\\\\awesome_GNN\\\\finetune.py'>"
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "importlib.reload(finetune)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "path_to_data = os.path.join('..', '..', 'data')\n",
    "path_to_models = os.path.join(path_to_data, 'finetuned_models')\n",
    "\n",
    "datasets = ['FGVC-Aircraft', 'StanfordCars']\n",
    "model_names = ['resnet', 'densenet', 'vgg']\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name:      resnet \n",
      "epochs:    30 \n",
      "occlusion: 0\n",
      "--------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 417/417 [00:11<00:00, 35.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total preds [75. 81. 87. ... 33. 19. 57.]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "importlib.reload(finetune)\n",
    "finetune.DATASET = 'FGVC-Aircraft'\n",
    "finetune.CLASSIFIER_INPUT_SIZE = 244\n",
    "\n",
    "# Get all different combinations of models\n",
    "load_path = os.path.join(path_to_models, 'FGVC-Aircraft', 'resnet', 'resnet_FGVC-Aircraft_E30_occ0.pth')\n",
    "save_path = os.path.join(path_to_data, 'testing_results')\n",
    "\n",
    "finetune.safe_mkdir(save_path)\n",
    "\n",
    "metrics = finetune.test_model(load_path, save_path, _verbose=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "outputs": [
    {
     "data": {
      "text/plain": "{'accuracy': 0.48574857485748574,\n 'precision': 0.5296528636047555,\n 'recall': 0.48574857485748574,\n 'f1': 0.48365305631321814,\n 'total_predicted': array([75., 81., 87., ..., 33., 19., 57.]),\n 'total_labels': array([75., 68., 88., ..., 33., 19., 57.])}"
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_score, recall_score, f1_score"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision : 0.5210819067203248\n",
      "recall : 0.47644764476447643\n",
      "f1 : 0.4750947438338586\n"
     ]
    }
   ],
   "source": [
    "print(f'precision : {precision(total_predictions, total_labels)}')\n",
    "print(f'recall : {recall(total_predictions, total_labels)}')\n",
    "print(f'f1 : {f1(total_predictions, total_labels)}')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Samplewise metrics are not available outside of multilabel classification.",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "Input \u001B[0;32mIn [47]\u001B[0m, in \u001B[0;36m<cell line: 1>\u001B[0;34m()\u001B[0m\n\u001B[0;32m----> 1\u001B[0m \u001B[43mprecision_score\u001B[49m\u001B[43m(\u001B[49m\u001B[43mlabels\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mnumpy\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mpreds\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mnumpy\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43maverage\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43msamples\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1757\u001B[0m, in \u001B[0;36mprecision_score\u001B[0;34m(y_true, y_pred, labels, pos_label, average, sample_weight, zero_division)\u001B[0m\n\u001B[1;32m   1628\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mprecision_score\u001B[39m(\n\u001B[1;32m   1629\u001B[0m     y_true,\n\u001B[1;32m   1630\u001B[0m     y_pred,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m   1636\u001B[0m     zero_division\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mwarn\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[1;32m   1637\u001B[0m ):\n\u001B[1;32m   1638\u001B[0m     \u001B[38;5;124;03m\"\"\"Compute the precision.\u001B[39;00m\n\u001B[1;32m   1639\u001B[0m \n\u001B[1;32m   1640\u001B[0m \u001B[38;5;124;03m    The precision is the ratio ``tp / (tp + fp)`` where ``tp`` is the number of\u001B[39;00m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m   1755\u001B[0m \u001B[38;5;124;03m    array([0.5, 1. , 1. ])\u001B[39;00m\n\u001B[1;32m   1756\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[0;32m-> 1757\u001B[0m     p, _, _, _ \u001B[38;5;241m=\u001B[39m \u001B[43mprecision_recall_fscore_support\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m   1758\u001B[0m \u001B[43m        \u001B[49m\u001B[43my_true\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1759\u001B[0m \u001B[43m        \u001B[49m\u001B[43my_pred\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1760\u001B[0m \u001B[43m        \u001B[49m\u001B[43mlabels\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mlabels\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1761\u001B[0m \u001B[43m        \u001B[49m\u001B[43mpos_label\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mpos_label\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1762\u001B[0m \u001B[43m        \u001B[49m\u001B[43maverage\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43maverage\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1763\u001B[0m \u001B[43m        \u001B[49m\u001B[43mwarn_for\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mprecision\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1764\u001B[0m \u001B[43m        \u001B[49m\u001B[43msample_weight\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43msample_weight\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1765\u001B[0m \u001B[43m        \u001B[49m\u001B[43mzero_division\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mzero_division\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1766\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1767\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m p\n",
      "File \u001B[0;32m~/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1548\u001B[0m, in \u001B[0;36mprecision_recall_fscore_support\u001B[0;34m(y_true, y_pred, beta, labels, pos_label, average, warn_for, sample_weight, zero_division)\u001B[0m\n\u001B[1;32m   1546\u001B[0m \u001B[38;5;66;03m# Calculate tp_sum, pred_sum, true_sum ###\u001B[39;00m\n\u001B[1;32m   1547\u001B[0m samplewise \u001B[38;5;241m=\u001B[39m average \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124msamples\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m-> 1548\u001B[0m MCM \u001B[38;5;241m=\u001B[39m \u001B[43mmultilabel_confusion_matrix\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m   1549\u001B[0m \u001B[43m    \u001B[49m\u001B[43my_true\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1550\u001B[0m \u001B[43m    \u001B[49m\u001B[43my_pred\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1551\u001B[0m \u001B[43m    \u001B[49m\u001B[43msample_weight\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43msample_weight\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1552\u001B[0m \u001B[43m    \u001B[49m\u001B[43mlabels\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mlabels\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1553\u001B[0m \u001B[43m    \u001B[49m\u001B[43msamplewise\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43msamplewise\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1554\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1555\u001B[0m tp_sum \u001B[38;5;241m=\u001B[39m MCM[:, \u001B[38;5;241m1\u001B[39m, \u001B[38;5;241m1\u001B[39m]\n\u001B[1;32m   1556\u001B[0m pred_sum \u001B[38;5;241m=\u001B[39m tp_sum \u001B[38;5;241m+\u001B[39m MCM[:, \u001B[38;5;241m0\u001B[39m, \u001B[38;5;241m1\u001B[39m]\n",
      "File \u001B[0;32m~/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:499\u001B[0m, in \u001B[0;36mmultilabel_confusion_matrix\u001B[0;34m(y_true, y_pred, sample_weight, labels, samplewise)\u001B[0m\n\u001B[1;32m    497\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m y_true\u001B[38;5;241m.\u001B[39mndim \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m1\u001B[39m:\n\u001B[1;32m    498\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m samplewise:\n\u001B[0;32m--> 499\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[1;32m    500\u001B[0m             \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mSamplewise metrics are not available outside of \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    501\u001B[0m             \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mmultilabel classification.\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    502\u001B[0m         )\n\u001B[1;32m    504\u001B[0m     le \u001B[38;5;241m=\u001B[39m LabelEncoder()\n\u001B[1;32m    505\u001B[0m     le\u001B[38;5;241m.\u001B[39mfit(labels)\n",
      "\u001B[0;31mValueError\u001B[0m: Samplewise metrics are not available outside of multilabel classification."
     ]
    }
   ],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[12 21 13 28 26  4  4  6]\n"
     ]
    }
   ],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}